{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9y3EQp7Cw3U",
        "outputId": "41119e08-15ee-476d-916e-d3dfe2630718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "negative\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast\n",
        "import torch\n",
        "\n",
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model = DistilBertForSequenceClassification.from_pretrained('/content/drive/MyDrive/Colab Notebooks/saved_model')\n",
        "model.to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('/content/drive/MyDrive/Colab Notebooks/saved_tokenizer')\n",
        "\n",
        "# Optional: Load the optimizer state\n",
        "optim = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
        "optim.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/saved_optimizer.pth'))\n",
        "\n",
        "# Define the prediction function\n",
        "def predict_sentiment(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
        "    inputs = {key: val.to(DEVICE) for key, val in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predicted_class = torch.argmax(logits, dim=1).item()\n",
        "    return 'positive' if predicted_class == 1 else 'negative'\n",
        "\n",
        "# Example usage\n",
        "test_review = \"The movie was not very good,but you can watch\"\n",
        "print(predict_sentiment(test_review))\n"
      ]
    }
  ]
}